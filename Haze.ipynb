{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.model' from 'models/model.pyc'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import utils as U\n",
    "reload(U)\n",
    "import image_loader as IM\n",
    "reload(IM)\n",
    "from theano.sandbox import cuda\n",
    "from keras.preprocessing import image\n",
    "%matplotlib inline\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, Input, Flatten, Conv2D, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "import models.model as M\n",
    "from keras.layers import Flatten, Dense, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "reload(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = \"data/train/\"\n",
    "train_folder = folder+\"train\"\n",
    "train_filenames = os.listdir(train_folder)\n",
    "validation_folder = folder+\"valid\"\n",
    "validation_filenames = os.listdir(validation_folder)\n",
    "batch_size = 44\n",
    "train_batch_count = len(train_filenames) / batch_size\n",
    "val_batch_count = len(validation_filenames) / batch_size\n",
    "\n",
    "mapping = U.atmospheric_mapping()\n",
    "\n",
    "train_labels = [ mapping[fname] for fname in train_filenames ]\n",
    "valid_labels = [ mapping[fname] for fname in validation_filenames ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(vertical_flip=True, horizontal_flip=True)\n",
    "\n",
    "gen = IM.DirectoryIterator(train_folder, train_filenames, image_processor=gen_t, one_hot_filename_mapping=mapping, batch_size=batch_size, shuffle=True)\n",
    "val_gen = IM.DirectoryIterator(validation_folder, validation_filenames, one_hot_filename_mapping=mapping, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre compute conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4237cdab4afc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDirectoryIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_filename_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDirectoryIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_filename_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_conv_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen_t' is not defined"
     ]
    }
   ],
   "source": [
    "conv_model = M.full_model()\n",
    "conv_model.load_weights(\"weights/atmospheric-full-training.07-1.78.hdf5\")\n",
    "conv_model = Sequential(conv_model.layers[:-len(M.dense_layers())])\n",
    "\n",
    "conv_model.compile(optimizer=(Adam(lr=0.0001)), metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "gen = IM.DirectoryIterator(train_folder, train_filenames, image_processor=gen_t, one_hot_filename_mapping=mapping, batch_size=batch_size, shuffle=False)\n",
    "val_gen = IM.DirectoryIterator(validation_folder, validation_filenames, one_hot_filename_mapping=mapping, batch_size=batch_size, shuffle=False)\n",
    "train_conv_features = conv_model.predict_generator(gen, train_batch_count, verbose=1)\n",
    "val_conv_features = conv_model.predict_generator(val_gen, val_batch_count, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dense Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_model = M.full_model(dropout=0.3, regularization=0.001)\n",
    "dense_model.load_weights(\"weights/atmospheric-full-training.07-1.78.hdf5\")\n",
    "flat = Flatten(input_shape=(8,8,512))\n",
    "dense_model = Sequential([flat] + dense_model.layers[-len(M.dense_layers()) + 1:])\n",
    "\n",
    "dense_model.compile(optimizer=(Adam(lr=0.001)), metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "\n",
    "train_conv_atmospheric_features = U.load_array(\"train_conv_atmospheric_features\")\n",
    "val_conv_atmospheric_features = U.load_array(\"valid_conv_atmospheric_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34816 samples, validate on 5632 samples\n",
      "Epoch 1/4\n",
      "34816/34816 [==============================] - 72s - loss: 1.8089 - acc: 0.8215 - val_loss: 0.7651 - val_acc: 0.7562\n",
      "Epoch 2/4\n",
      "34816/34816 [==============================] - 74s - loss: 1.6418 - acc: 0.8321 - val_loss: 0.4349 - val_acc: 0.8473\n",
      "Epoch 3/4\n",
      "34816/34816 [==============================] - 83s - loss: 1.5730 - acc: 0.8378 - val_loss: 0.5762 - val_acc: 0.8191\n",
      "Epoch 4/4\n",
      "34816/34816 [==============================] - 83s - loss: 1.6045 - acc: 0.8325 - val_loss: 0.4445 - val_acc: 0.8542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f221af41e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = { 0: 13.6, 1: 3.9, 2: 10.5, 3: 1 }\n",
    "dense_model.fit(train_conv_atmospheric_features, train_labels, class_weight=weights, batch_size=64, validation_data=(val_conv_atmospheric_features, valid_labels), epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34816 samples, validate on 5632 samples\n",
      "Epoch 1/6\n",
      "34816/34816 [==============================] - 245s - loss: 3.6899 - acc: 0.8122 - val_loss: 2.6995 - val_acc: 0.8226\n",
      "Epoch 2/6\n",
      "34816/34816 [==============================] - 244s - loss: 4.7218 - acc: 0.8150 - val_loss: 3.3845 - val_acc: 0.8331\n",
      "Epoch 3/6\n",
      "34816/34816 [==============================] - 244s - loss: 4.8040 - acc: 0.8206 - val_loss: 2.9306 - val_acc: 0.8606\n",
      "Epoch 4/6\n",
      "34816/34816 [==============================] - 244s - loss: 5.1760 - acc: 0.8161 - val_loss: 3.3343 - val_acc: 0.8640\n",
      "Epoch 5/6\n",
      "34816/34816 [==============================] - 244s - loss: 5.0445 - acc: 0.8175 - val_loss: 3.4123 - val_acc: 0.8100\n",
      "Epoch 6/6\n",
      "34816/34816 [==============================] - 244s - loss: 5.0092 - acc: 0.8184 - val_loss: 2.9689 - val_acc: 0.8427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f235dd23390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = { 0: 13.6, 1: 3.9, 2: 10.5, 3: 1 }\n",
    "dense_model.fit(train_conv_atmospheric_features, train_labels, class_weight=weights, batch_size=64, validation_data=(val_conv_atmospheric_features, valid_labels), epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "276/791 [=========>....................] - ETA: 3475s - loss: 1.4952 - acc: 0.8412"
     ]
    }
   ],
   "source": [
    "model = M.full_model()\n",
    "model.load_weights(\"weights/atmospheric-full-training.07-1.78.hdf5\")\n",
    "\n",
    "weights = { 0: 13.6, 1: 3.9, 2: 10.5, 3: 1 }\n",
    "model.compile(optimizer=(Adam(lr=0.0001)), metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint, BaseLogger, History, CSVLogger\n",
    "callbacks = [\n",
    "    History(),\n",
    "    BaseLogger(),\n",
    "    ModelCheckpoint(\"weights/3-a-atmospheric-full-training.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor=\"val_loss\", verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1),\n",
    "    CSVLogger(\"results/atmospheric_3.csv\", separator=',', append=False)\n",
    "]\n",
    "\n",
    " \n",
    "model.fit_generator(gen, train_batch_count, class_weight=weights, epochs=4, validation_data=val_gen, validation_steps=val_batch_count, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(gen, train_batch_count, class_weight=weights, epochs=14, validation_data=val_gen, validation_steps=val_batch_count, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
